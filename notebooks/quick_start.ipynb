{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Underwriting Decisioning System - Quick Start\n",
    "\n",
    "This notebook demonstrates the complete workflow of the credit underwriting decisioning system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from data.synthetic_generator import generate_synthetic_credit_data\n",
    "from models.train import (\n",
    "    CreditModel, \n",
    "    time_based_split, \n",
    "    prepare_features, \n",
    "    evaluate_model\n",
    ")\n",
    "from scoring.scorecard import ScorecardMapper\n",
    "from monitoring.drift import DriftMonitor, calculate_psi\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "df = generate_synthetic_credit_data(n_samples=5000, default_rate=0.15)\n",
    "\n",
    "print(f\"Generated {len(df)} applications\")\n",
    "print(f\"Default rate: {df['default'].mean():.2%}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "features_to_plot = ['credit_score', 'annual_income', 'debt_to_income', \n",
    "                   'credit_utilization', 'num_delinquencies', 'employment_length_years']\n",
    "\n",
    "for idx, feature in enumerate(features_to_plot):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    ax.hist(df[feature], bins=30, alpha=0.7, edgecolor='black')\n",
    "    ax.set_title(f'{feature}')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based split\n",
    "train_df, cal_df, test_df = time_based_split(df, 'application_date')\n",
    "print(f\"Train: {len(train_df)}, Calibration: {len(cal_df)}, Test: {len(test_df)}\")\n",
    "\n",
    "# Prepare features\n",
    "X_train, y_train = prepare_features(train_df)\n",
    "X_cal, y_cal = prepare_features(cal_df)\n",
    "X_test, y_test = prepare_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "lr_model = CreditModel(model_type='logistic', calibrate=True)\n",
    "lr_model.train(X_train, y_train, X_cal, y_cal)\n",
    "\n",
    "# Train Gradient Boosting\n",
    "gb_model = CreditModel(model_type='gradient_boosting', calibrate=True)\n",
    "gb_model.train(X_train, y_train, X_cal, y_cal)\n",
    "\n",
    "print(\"Models trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "y_pred_lr = lr_model.predict_proba(X_test)\n",
    "y_pred_gb = gb_model.predict_proba(X_test)\n",
    "\n",
    "lr_metrics = evaluate_model(y_test, y_pred_lr, 'Logistic Regression')\n",
    "gb_metrics = evaluate_model(y_test, y_pred_gb, 'Gradient Boosting')\n",
    "\n",
    "metrics_df = pd.DataFrame([lr_metrics, gb_metrics]).T\n",
    "metrics_df.columns = ['Logistic Regression', 'Gradient Boosting']\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scorecard Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scorecard mapper\n",
    "mapper = ScorecardMapper(score0=600, odds0=50, pdo=20)\n",
    "mapper.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert probabilities to scores\n",
    "scores = mapper.prob_to_score(y_pred_gb)\n",
    "\n",
    "# Visualize score distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(y_pred_gb, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Default Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Probability Distribution')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(scores, bins=50, alpha=0.7, edgecolor='black', color='orange')\n",
    "plt.xlabel('Credit Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Score Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nScore Statistics:\")\n",
    "print(f\"  Mean: {scores.mean():.1f}\")\n",
    "print(f\"  Median: {np.median(scores):.1f}\")\n",
    "print(f\"  Std Dev: {scores.std():.1f}\")\n",
    "print(f\"  Range: [{scores.min():.0f}, {scores.max():.0f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Drift Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train data as baseline and test data as current\n",
    "monitor = DriftMonitor(baseline_data=train_df)\n",
    "\n",
    "# Add scores to test data for monitoring\n",
    "test_with_scores = test_df.copy()\n",
    "test_with_scores['predicted_score'] = mapper.prob_to_score(y_pred_gb)\n",
    "\n",
    "# Monitor drift\n",
    "report = monitor.monitor(\n",
    "    test_with_scores,\n",
    "    feature_cols=['credit_score', 'annual_income', 'debt_to_income'],\n",
    "    score_col='predicted_score'\n",
    ")\n",
    "\n",
    "print(\"Drift Monitoring Report\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Baseline samples: {report['baseline_samples']}\")\n",
    "print(f\"Current samples: {report['current_samples']}\")\n",
    "\n",
    "print(\"\\nFeature PSI:\")\n",
    "for feature, metrics in report['feature_psi'].items():\n",
    "    print(f\"  {feature}: PSI = {metrics['psi']:.4f}\")\n",
    "\n",
    "if report['score_psi']:\n",
    "    print(f\"\\nScore PSI: {report['score_psi']['psi']:.4f}\")\n",
    "\n",
    "if report['alerts']:\n",
    "    print(f\"\\nAlerts: {len(report['alerts'])}\")\n",
    "    for alert in report['alerts']:\n",
    "        print(f\"  [{alert['severity'].upper()}] {alert['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Score New Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample application\n",
    "sample_app = pd.DataFrame([{\n",
    "    'credit_score': 720,\n",
    "    'num_credit_lines': 5,\n",
    "    'credit_utilization': 0.3,\n",
    "    'num_delinquencies': 0,\n",
    "    'months_since_last_delinq': -1,\n",
    "    'annual_income': 75000,\n",
    "    'employment_length_years': 5,\n",
    "    'debt_to_income': 0.25,\n",
    "    'loan_amount': 15000,\n",
    "    'loan_term_months': 36,\n",
    "    'interest_rate': 8.5,\n",
    "    'num_inquiries_6m': 1,\n",
    "    'revolving_balance': 5000,\n",
    "    'has_mortgage': 1,\n",
    "    'has_car_loan': 0\n",
    "}])\n",
    "\n",
    "# Score\n",
    "prob = gb_model.predict_proba(sample_app)[0]\n",
    "score = mapper.prob_to_score(np.array([prob]))[0]\n",
    "\n",
    "# Decision\n",
    "if prob < 0.10:\n",
    "    decision = \"Approve\"\n",
    "elif prob < 0.20:\n",
    "    decision = \"Review\"\n",
    "else:\n",
    "    decision = \"Decline\"\n",
    "\n",
    "print(\"Sample Application Scoring Result:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Default Probability: {prob:.4f}\")\n",
    "print(f\"Credit Score: {score:.0f}\")\n",
    "print(f\"Decision: {decision}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
